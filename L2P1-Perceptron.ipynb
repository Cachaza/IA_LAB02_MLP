{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practica 2 - Parte 1\n",
    "### Perceptron\n",
    "\n",
    "#### Importar librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset:\n",
    "Cargamos el dataset de iris de la libreria sklearn, al cargar load_iris en iris obtenemos diferentes sets de informacion, guardamos la informacion que nos interesa en un daframe de pandas.\n",
    "\n",
    "Elimino del dataset los de target = 2 por que solo tenemos que diferenciar entre 2 tipos de iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                 5.1               3.5                1.4               0.2   \n",
       "1                 4.9               3.0                1.4               0.2   \n",
       "2                 4.7               3.2                1.3               0.2   \n",
       "3                 4.6               3.1                1.5               0.2   \n",
       "4                 5.0               3.6                1.4               0.2   \n",
       "..                ...               ...                ...               ...   \n",
       "95                5.7               3.0                4.2               1.2   \n",
       "96                5.7               2.9                4.2               1.3   \n",
       "97                6.2               2.9                4.3               1.3   \n",
       "98                5.1               2.5                3.0               1.1   \n",
       "99                5.7               2.8                4.1               1.3   \n",
       "\n",
       "    target  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "..     ...  \n",
       "95     1.0  \n",
       "96     1.0  \n",
       "97     1.0  \n",
       "98     1.0  \n",
       "99     1.0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                        columns= iris['feature_names'] + ['target'])\n",
    "iris_df = iris_df.query('target != 2')\n",
    "iris_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para nomralizar con L2 las 4 primeras columnas del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_l2(df, columns):\n",
    "  \"\"\"\n",
    "  Normalizes specified columns in a dataframe using L2 norm.\n",
    "\n",
    "  Args:\n",
    "      df: The pandas dataframe.\n",
    "      columns: List of column names to normalize.\n",
    "\n",
    "  Returns:\n",
    "      A new dataframe with normalized columns.\n",
    "  \"\"\"\n",
    "  df_norm = df.copy()\n",
    "  for col in columns:\n",
    "    # Calculate L2 norm for each row\n",
    "    norm = df[col].apply(lambda x: np.sqrt(sum(x**2 for x in df[col])))\n",
    "\n",
    "    # Avoid division by zero (rows with all zeros)\n",
    "    norm[norm == 0] = 1\n",
    "\n",
    "    # Normalize the column values\n",
    "    df_norm[col] = df[col] / norm\n",
    "  return df_norm\n",
    "\n",
    "# Normalize the first 4 columns\n",
    "iris_normalizados = normalize_l2(iris_df.copy(), iris_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setosa = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables para el perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_entradas = 2\n",
    "tasa_aprendizaje = 0.1\n",
    "iteraciones = 100\n",
    "umbral = 0.1\n",
    "pesosIniciales = np.random.uniform(-1.0, 1.0, size=(num_entradas,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con el 60% de los datos para entrenar y el 40% para comprobar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos con la columna 0 y 2 de los datos\n",
    "iris_datos_2_datos_y_target = iris_normalizados.iloc[:, [0, 2, 4]].values\n",
    "\n",
    "num_datos = len(iris_datos_2_datos_y_target)\n",
    "num_datos_entrenamiento = int(num_datos * 0.6)\n",
    "num_datos_test = num_datos - num_datos_entrenamiento\n",
    "\n",
    "np.random.shuffle(iris_datos_2_datos_y_target)\n",
    "\n",
    "iris_entrenamiento = iris_datos_2_datos_y_target[:num_datos_entrenamiento]\n",
    "iris_test = iris_datos_2_datos_y_target[num_datos_entrenamiento:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entrenamiento\n",
    "* Función de activación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_func(value):    #Tangent Hypotenuse\n",
    "    #return (1/(1+np.exp(-value)))\n",
    "    return ((np.exp(value)-np.exp(-value))/(np.exp(value)+np.exp(-value)))\n",
    "\n",
    "def perceptron_train(in_data,labels,eta, umbral):\n",
    "    X=np.array(in_data)\n",
    "    y=np.array(labels)\n",
    "    weights= pesosIniciales.copy()\n",
    "    for key in range(X.shape[0]):\n",
    "        a=activation_func(np.matmul(np.transpose(weights),X[key]))     \n",
    "        yn=0\n",
    "        if a>=umbral:\n",
    "            yn=1\n",
    "        elif a<=(-umbral):\n",
    "            yn=-1\n",
    "        weights=weights+eta*(yn-y[key])*X[key]\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comprobar resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_test(in_data,label_shape,weights, umbral):\n",
    "    X=np.array(in_data)\n",
    "    y=np.zeros(label_shape)\n",
    "    for key in range(X.shape[1]):\n",
    "        a=activation_func((weights*X[key]).sum())\n",
    "        y[key]=0\n",
    "        if a>=umbral:\n",
    "            y[key]=1\n",
    "        elif a<=(-umbral):\n",
    "            y[key]=-1\n",
    "    return y\n",
    "\n",
    "def score(result,labels):\n",
    "    difference=result-np.array(labels)                                                        \n",
    "    correct_ctr=0\n",
    "    for elem in range(difference.shape[0]):\n",
    "        if difference[elem]==0:\n",
    "            correct_ctr+=1\n",
    "    score=correct_ctr*100/difference.size\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aprendizaje: 0.01\n",
      "Umbral: 0.0\n",
      "Pesos finales: [0.49730964 0.97077075]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.01\n",
      "Umbral: 0.1\n",
      "Pesos finales: [0.47211053 0.95822386]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.01\n",
      "Umbral: 0.2\n",
      "Pesos finales: [0.43823334 0.9163697 ]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.01\n",
      "Umbral: 0.3\n",
      "Pesos finales: [0.43823334 0.9163697 ]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.01\n",
      "Umbral: 0.4\n",
      "Pesos finales: [0.43823334 0.9163697 ]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.05\n",
      "Umbral: 0.0\n",
      "Pesos finales: [0.5981061 1.0209583]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.05\n",
      "Umbral: 0.1\n",
      "Pesos finales: [0.47211053 0.95822386]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.05\n",
      "Umbral: 0.2\n",
      "Pesos finales: [0.30272456 0.74895302]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.05\n",
      "Umbral: 0.3\n",
      "Pesos finales: [0.30272456 0.74895302]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.05\n",
      "Umbral: 0.4\n",
      "Pesos finales: [0.30272456 0.74895302]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.1\n",
      "Umbral: 0.0\n",
      "Pesos finales: [0.72410166 1.08369274]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.1\n",
      "Umbral: 0.1\n",
      "Pesos finales: [0.47211053 0.95822386]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.1\n",
      "Umbral: 0.2\n",
      "Pesos finales: [0.13333859 0.53968217]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.1\n",
      "Umbral: 0.3\n",
      "Pesos finales: [0.13333859 0.53968217]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.1\n",
      "Umbral: 0.4\n",
      "Pesos finales: [0.13333859 0.53968217]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.5\n",
      "Umbral: 0.0\n",
      "Pesos finales: [1.73206619 1.58556823]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.5\n",
      "Umbral: 0.1\n",
      "Pesos finales: [0.47211053 0.95822386]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.5\n",
      "Umbral: 0.2\n",
      "Pesos finales: [-1.51767535 -1.48717073]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.5\n",
      "Umbral: 0.3\n",
      "Pesos finales: [-1.22174917 -1.13448459]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 0.5\n",
      "Umbral: 0.4\n",
      "Pesos finales: [-1.22174917 -1.13448459]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 1.0\n",
      "Umbral: 0.0\n",
      "Pesos finales: [2.99202184 2.2129126 ]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 1.0\n",
      "Umbral: 0.1\n",
      "Pesos finales: [0.47211053 0.95822386]\n",
      "Puntuación: 60.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 1.0\n",
      "Umbral: 0.2\n",
      "Pesos finales: [-6.56475997 -6.40448939]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 1.0\n",
      "Umbral: 0.3\n",
      "Pesos finales: [-5.8839482  -5.84580958]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n",
      "Tasa de aprendizaje: 1.0\n",
      "Umbral: 0.4\n",
      "Pesos finales: [-4.58223608 -4.87826354]\n",
      "Puntuación: 55.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "datos_entrenamiento = iris_entrenamiento[:, :-1]\n",
    "target_entrenamiento = iris_entrenamiento[:, -1]\n",
    "\n",
    "datos_test = iris_test[:, :-1]\n",
    "indices_test = iris_test[:, -1]\n",
    "# Lista de learning rates\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "\n",
    "# Lista de umbrales\n",
    "umbrales = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "for coeficiente_aprendizaje in learning_rates:\n",
    "  for umbral in umbrales:\n",
    "    pesos_finales = perceptron_train(datos_entrenamiento, target_entrenamiento, coeficiente_aprendizaje, umbral)\n",
    "    resultados = perceptron_test(datos_test, indices_test.shape, pesos_finales, umbral)\n",
    "    puntuacion = score(resultados, indices_test)\n",
    "    print(\"Tasa de aprendizaje:\", tasa_aprendizaje)\n",
    "    print(\"Umbral:\", umbral)\n",
    "    print(\"Pesos finales:\", pesos_finales)\n",
    "    print(\"Puntuación:\", puntuacion)\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47211053, 0.95822386])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesosIniciales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
